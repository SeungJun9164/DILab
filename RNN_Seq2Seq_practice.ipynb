{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ko                                             en\n",
       "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.\n",
       "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.\n",
       "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.\n",
       "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.\n",
       "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\1.구어체.xlsx', sheet_name=1, usecols=[1, 2], names=['ko', 'en'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ko  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                  en  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\2.대화체.xlsx', sheet_name=2, usecols=[5, 6], names=['ko', 'en'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>하늘길 운항노선도 광주-제주 광주-양양 광주-김해 등 국내는 물론 일본과 중국 등 ...</td>\n",
       "      <td>The airway route will be gradually expanded do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저가항공보다는 프레미엄 비즈니스 전문 항공사를 추구하는 에어필립은 지방 도시간 항공...</td>\n",
       "      <td>It is expected that Air Philip, which seeks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>울릉도와 흑산도 등의 소형공항이 수년 내 문을 열 경우 광주․전남 지역민의 관광 접...</td>\n",
       "      <td>If small airport such as Ulleungdo and Heuksan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지역민들이 해외여행을 위해 인천공항에 갈 때마다 고속버스에 ‘수화물’을 싣고 내리던...</td>\n",
       "      <td>It mitigated inconvenience of local people tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>포항출신인 필립에셋 엄일석 회장은 “광주에 18년 동안 살면서 강원도나 인천공항에 ...</td>\n",
       "      <td>Eom Il-seok, president of Phillip Asset, who i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ko  \\\n",
       "0  하늘길 운항노선도 광주-제주 광주-양양 광주-김해 등 국내는 물론 일본과 중국 등 ...   \n",
       "1  저가항공보다는 프레미엄 비즈니스 전문 항공사를 추구하는 에어필립은 지방 도시간 항공...   \n",
       "2  울릉도와 흑산도 등의 소형공항이 수년 내 문을 열 경우 광주․전남 지역민의 관광 접...   \n",
       "3  지역민들이 해외여행을 위해 인천공항에 갈 때마다 고속버스에 ‘수화물’을 싣고 내리던...   \n",
       "4  포항출신인 필립에셋 엄일석 회장은 “광주에 18년 동안 살면서 강원도나 인천공항에 ...   \n",
       "\n",
       "                                                  en  \n",
       "0  The airway route will be gradually expanded do...  \n",
       "1  It is expected that Air Philip, which seeks fo...  \n",
       "2  If small airport such as Ulleungdo and Heuksan...  \n",
       "3  It mitigated inconvenience of local people tha...  \n",
       "4  Eom Il-seok, president of Phillip Asset, who i...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_excel('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\3.문어체-뉴스.xlsx', sheet_name=0, usecols=[7, 8], names=['ko', 'en'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>끝으로 “탈퇴 조치가 우리(미국)의 인권헌신에 있어 후퇴가 아니라는 점을 분명히 하...</td>\n",
       "      <td>Finally, he explained, \"I want to make it clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나 PD는 이어 “내 개인의 명예와 가정이 걸린 만큼 선처는 없을 것”이라면서 “C...</td>\n",
       "      <td>Producer Na went on to say, \"There will be no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나경원 자유한국당 원내대표 등 원내대표단이 30일 강원도 인제군 서화면 육군 12사...</td>\n",
       "      <td>Na Kyung-won, floor leader of the main opposit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나경원 한국당 원내대표는 이날 국회에서 ‘경제비상 극복, 무엇을 해야 하나’ 간담회...</td>\n",
       "      <td>In a meeting at the National Assembly, 'What s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>끈질긴 매체와 이미지 실험, 물성과 질감 탐구를 거친 이정진의 섬세한 작업은 깊고 ...</td>\n",
       "      <td>Lee Jung-jin's delicate work, which has underg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ko  \\\n",
       "0  끝으로 “탈퇴 조치가 우리(미국)의 인권헌신에 있어 후퇴가 아니라는 점을 분명히 하...   \n",
       "1  나 PD는 이어 “내 개인의 명예와 가정이 걸린 만큼 선처는 없을 것”이라면서 “C...   \n",
       "2  나경원 자유한국당 원내대표 등 원내대표단이 30일 강원도 인제군 서화면 육군 12사...   \n",
       "3  나경원 한국당 원내대표는 이날 국회에서 ‘경제비상 극복, 무엇을 해야 하나’ 간담회...   \n",
       "4  끈질긴 매체와 이미지 실험, 물성과 질감 탐구를 거친 이정진의 섬세한 작업은 깊고 ...   \n",
       "\n",
       "                                                  en  \n",
       "0  Finally, he explained, \"I want to make it clea...  \n",
       "1  Producer Na went on to say, \"There will be no ...  \n",
       "2  Na Kyung-won, floor leader of the main opposit...  \n",
       "3  In a meeting at the National Assembly, 'What s...  \n",
       "4  Lee Jung-jin's delicate work, which has underg...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_excel('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\3.문어체-뉴스.xlsx', sheet_name=1, usecols=[7, 9], names=['ko', 'en'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ko                                             en\n",
       "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.\n",
       "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.\n",
       "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.\n",
       "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.\n",
       "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "      <td>0.966454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "      <td>0.440733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "      <td>0.007491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "      <td>0.910976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "      <td>0.939269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ko                                             en  \\\n",
       "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.   \n",
       "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.   \n",
       "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.   \n",
       "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.   \n",
       "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up.   \n",
       "\n",
       "       prob  \n",
       "0  0.966454  \n",
       "1  0.440733  \n",
       "2  0.007491  \n",
       "3  0.910976  \n",
       "4  0.939269  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prob'] = [random.random() for _ in range(len(df))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(prob):\n",
    "    if prob < 0.6:\n",
    "        return 'train'\n",
    "    elif prob < 0.8:\n",
    "        return 'valid'\n",
    "    else:\n",
    "        return 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>prob</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "      <td>0.966454</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "      <td>0.440733</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "      <td>0.910976</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "      <td>0.939269</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53911</th>\n",
       "      <td>구체적인 것에 분노하고 여론이 한껏 달아올랐을 때 해야 하는데 일단 그런 게 없고,...</td>\n",
       "      <td>It should be done when the public is angry at ...</td>\n",
       "      <td>0.557385</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53912</th>\n",
       "      <td>구체적인 기자회견 내용은 알려지지 않았지만 결국 최근의 의혹에 대한 입장을 표명하는...</td>\n",
       "      <td>The details of the press conference were not k...</td>\n",
       "      <td>0.495226</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53913</th>\n",
       "      <td>구체적인 내용은 북·미 간 협상에서 논의될 사안이지만 이번 정상회담에서 핵 리스트를...</td>\n",
       "      <td>Even though the specific details will be discu...</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53914</th>\n",
       "      <td>구체적인 내용은 후속회담과 실무협상에서 다루기로 했지만 두 정상은 앞으로도 정상외교...</td>\n",
       "      <td>Although the details of the talks will be disc...</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53915</th>\n",
       "      <td>구체적인 로드맵으로는 북중러 접경 지역 경제특구의 개발, 남·북·러 3각 물류 협력...</td>\n",
       "      <td>Specific road maps include the development of ...</td>\n",
       "      <td>0.731899</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157973 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ko  \\\n",
       "0                             나는 매일 저녁 배트를 만나러 다락방으로 가요.   \n",
       "1                                     선생님 이문장이 이해가 안 가요.   \n",
       "2                               컴퓨터를 시작하면 시간이 너무 빠르게 가요.   \n",
       "3                                  나는 오늘 자정에 한국으로 돌아 가요.   \n",
       "4                                     나는 일어나자마자 화장실에 가요.   \n",
       "...                                                  ...   \n",
       "53911  구체적인 것에 분노하고 여론이 한껏 달아올랐을 때 해야 하는데 일단 그런 게 없고,...   \n",
       "53912  구체적인 기자회견 내용은 알려지지 않았지만 결국 최근의 의혹에 대한 입장을 표명하는...   \n",
       "53913  구체적인 내용은 북·미 간 협상에서 논의될 사안이지만 이번 정상회담에서 핵 리스트를...   \n",
       "53914  구체적인 내용은 후속회담과 실무협상에서 다루기로 했지만 두 정상은 앞으로도 정상외교...   \n",
       "53915  구체적인 로드맵으로는 북중러 접경 지역 경제특구의 개발, 남·북·러 3각 물류 협력...   \n",
       "\n",
       "                                                      en      prob  class  \n",
       "0           I go to the attic every evening to meet Bat.  0.966454   test  \n",
       "1            Sir, I don't understand this sentence here.  0.440733  train  \n",
       "2          Time flies when you start using the computer.  0.007491  train  \n",
       "3             I'm going back to Korea today at midnight.  0.910976   test  \n",
       "4                 I go to bathroom as soon as I wake up.  0.939269   test  \n",
       "...                                                  ...       ...    ...  \n",
       "53911  It should be done when the public is angry at ...  0.557385  train  \n",
       "53912  The details of the press conference were not k...  0.495226  train  \n",
       "53913  Even though the specific details will be discu...  0.166034  train  \n",
       "53914  Although the details of the talks will be disc...  0.904523   test  \n",
       "53915  Specific road maps include the development of ...  0.731899  valid  \n",
       "\n",
       "[157973 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['prob'].apply(split_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>지금 잠을 자면 깨어나지 못할 거 같아서 지금 가요.</td>\n",
       "      <td>If I fall asleep I might not get up so I will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>대한민국 남자라면 모두 20 대에 의무적으로 군대에 가요.</td>\n",
       "      <td>Korean men have to obligatorily join the army ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오늘은 새 자동차를 받으러 가요.</td>\n",
       "      <td>Today, I am going to pick up the new car.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ko  \\\n",
       "1                선생님 이문장이 이해가 안 가요.   \n",
       "2          컴퓨터를 시작하면 시간이 너무 빠르게 가요.   \n",
       "5     지금 잠을 자면 깨어나지 못할 거 같아서 지금 가요.   \n",
       "7  대한민국 남자라면 모두 20 대에 의무적으로 군대에 가요.   \n",
       "9                오늘은 새 자동차를 받으러 가요.   \n",
       "\n",
       "                                                  en  \n",
       "1        Sir, I don't understand this sentence here.  \n",
       "2      Time flies when you start using the computer.  \n",
       "5  If I fall asleep I might not get up so I will ...  \n",
       "7  Korean men have to obligatorily join the army ...  \n",
       "9          Today, I am going to pick up the new car.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['class'] == 'train'][['ko', 'en']]\n",
    "df_valid = df[df['class'] == 'valid'][['ko', 'en']]\n",
    "df_test = df[df['class'] == 'test'][['ko', 'en']]\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94463, 31688, 31822)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_valid), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\train_data.csv', index=False)\n",
    "df_valid.to_csv('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\valid_data.csv', index=False)\n",
    "df_test.to_csv('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "from eunjeon import Mecab\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ko(text):\n",
    "    return [tok for tok in mecab.morphs(text)][::-1]\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_ko, init_token='<sos>', eos_token='<eos>')\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'ko':('src', SRC), 'en':('trg', TRG)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(path = 'C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq',\n",
    "                                             train = 'train_data.csv',\n",
    "                                             test = 'test_data.csv',\n",
    "                                             format = 'csv',\n",
    "                                             fields = fields)\n",
    "valid_data = TabularDataset('C:\\\\Users\\\\abc\\\\jupyter\\\\pytorch\\\\Seq2Seq\\\\valid_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 94463\n",
      "Number of validation examples: 31688\n",
      "Number of testing examples: 31822\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data.examples)}')\n",
    "print(f'Number of validation examples: {len(valid_data.examples)}')\n",
    "print(f'Number of testing examples: {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x:len(x.src),\n",
    "    sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"Encoder and Decoder must have equal numver of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(33056, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(24617, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=24617, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,551,913 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 785.63 MiB already allocated; 55.13 MiB free; 964.00 MiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FFCB54175A200007FFCB5417540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFCB53B9C0600007FFCB53B9B90 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FFCB53C069600007FFCB53BF370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFCB53C083A00007FFCB53BF370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFCB53B509900007FFCB53B4EB0 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FFC42CB1FF100007FFC42CB1EB0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FFC42DC8AFE00007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC42DC42A500007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC3ADC1A3A00007FFC3ADAD9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFC3ADC000500007FFC3ADAD9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFC3AE918A000007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AEA28DC00007FFC3AEA2850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FFC3AC65C6100007FFC3AC65780 torch_cpu.dll!at::native::empty_like [<unknown file> @ <unknown line number>]\n00007FFC3AF671C200007FFC3AEED060 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFC3AA221EE00007FFC3AA16470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFC3AE8F44F00007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AEA2C8200007FFC3AEA2C00 torch_cpu.dll!at::empty_like [<unknown file> @ <unknown line number>]\n00007FFC4252022600007FFC42513E60 torch_cuda.dll!at::native::cat_out_cuda [<unknown file> @ <unknown line number>]\n00007FFC4253BD4A00007FFC4253BCC0 torch_cuda.dll!at::native::log_softmax_backward_cuda [<unknown file> @ <unknown line number>]\n00007FFC42DB386D00007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC42DC1A6800007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC3AE8EC6600007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AE768FE00007FFC3AE76890 torch_cpu.dll!at::_log_softmax_backward_data [<unknown file> @ <unknown line number>]\n00007FFC3C202BE000007FFC3C12E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFC3AA20B2800007FFC3AA16470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFC3AE8EC6600007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AE768FE00007FFC3AE76890 torch_cpu.dll!at::_log_softmax_backward_data [<unknown file> @ <unknown line number>]\n00007FFC3C0899DC00007FFC3C089870 torch_cpu.dll!torch::autograd::generated::LogSoftmaxBackward::apply [<unknown file> @ <unknown line number>]\n00007FFC3C067E9100007FFC3C067B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFC3C5CF9BA00007FFC3C5CF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFC3C5D03AD00007FFC3C5CFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFC3C5D4FE200007FFC3C5D4CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFC3C5D4C4100007FFC3C5D4BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFC8BDB08F700007FFC8BD89F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFC3C5CBF1400007FFC3C5CB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFCC2BA14C200007FFCC2BA1430 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFCC3576FD400007FFCC3576FC0 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFCC53DCEC100007FFCC53DCEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-6cc52f3de18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-f48a3abf85c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 785.63 MiB already allocated; 55.13 MiB free; 964.00 MiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FFCB54175A200007FFCB5417540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFCB53B9C0600007FFCB53B9B90 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FFCB53C069600007FFCB53BF370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFCB53C083A00007FFCB53BF370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFCB53B509900007FFCB53B4EB0 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FFC42CB1FF100007FFC42CB1EB0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FFC42DC8AFE00007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC42DC42A500007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC3ADC1A3A00007FFC3ADAD9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFC3ADC000500007FFC3ADAD9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFC3AE918A000007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AEA28DC00007FFC3AEA2850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FFC3AC65C6100007FFC3AC65780 torch_cpu.dll!at::native::empty_like [<unknown file> @ <unknown line number>]\n00007FFC3AF671C200007FFC3AEED060 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFC3AA221EE00007FFC3AA16470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFC3AE8F44F00007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AEA2C8200007FFC3AEA2C00 torch_cpu.dll!at::empty_like [<unknown file> @ <unknown line number>]\n00007FFC4252022600007FFC42513E60 torch_cuda.dll!at::native::cat_out_cuda [<unknown file> @ <unknown line number>]\n00007FFC4253BD4A00007FFC4253BCC0 torch_cuda.dll!at::native::log_softmax_backward_cuda [<unknown file> @ <unknown line number>]\n00007FFC42DB386D00007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC42DC1A6800007FFC42D6E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFC3AE8EC6600007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AE768FE00007FFC3AE76890 torch_cpu.dll!at::_log_softmax_backward_data [<unknown file> @ <unknown line number>]\n00007FFC3C202BE000007FFC3C12E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFC3AA20B2800007FFC3AA16470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFC3AE8EC6600007FFC3AE88FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFC3AE768FE00007FFC3AE76890 torch_cpu.dll!at::_log_softmax_backward_data [<unknown file> @ <unknown line number>]\n00007FFC3C0899DC00007FFC3C089870 torch_cpu.dll!torch::autograd::generated::LogSoftmaxBackward::apply [<unknown file> @ <unknown line number>]\n00007FFC3C067E9100007FFC3C067B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFC3C5CF9BA00007FFC3C5CF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFC3C5D03AD00007FFC3C5CFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFC3C5D4FE200007FFC3C5D4CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFC3C5D4C4100007FFC3C5D4BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFC8BDB08F700007FFC8BD89F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFC3C5CBF1400007FFC3C5CB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFCC2BA14C200007FFCC2BA1430 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFCC3576FD400007FFCC3576FC0 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFCC53DCEC100007FFCC53DCEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "N_EPOCH = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
